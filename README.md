
---

## ğŸ§  Project Overview

- **Problem**: Traditional denoising models require clean images which are often unavailable in practice.
- **Solution**: We use blind-spot networks and a novel DIL strategy to train only on noisy data.
- **Goal**: Achieve competitive denoising results without relying on ground-truth clean targets.

---

## ğŸ—ï¸ Model Architecture

- **Encoder-decoder backbone (UNet-based)**
- **Blind-spot convolutional masking**
- **Conditional context blocks**
- **Downsampled Invariance Loss function**

No architecture diagram is used. Please refer to the `paper/` folder for detailed textual explanation.

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ paper/
â”‚   â”œâ”€â”€ Image Denoising Case Study.docx       # Full research paper (8 pages)
â”‚   â””â”€â”€ Cover_Title_Page.docx                 # Title page for submission
â”œâ”€â”€ presentation/
â”‚   â””â”€â”€ SelfSupervised_ImageDenoising_Presentation.pptx
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                              # Model training script
â”‚   â”œâ”€â”€ cbn_model.py                          # Model architecture (CBN)
â”‚   â”œâ”€â”€ utils.py                              # Utility functions
â”‚   â”œâ”€â”€ loss_functions.py                     # DIL + hybrid losses
â”‚   â””â”€â”€ evaluate.py                           # PSNR / SSIM evaluation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ BSD68/                                # Benchmark dataset
â”‚   â””â”€â”€ RealNoise/                            # Real-world noisy images
â”œâ”€â”€ results/
â”‚   â””â”€â”€ visual_comparisons/                   # Placeholders for output samples
â”œâ”€â”€ video/
â”‚   â””â”€â”€ video_script.txt                      # Script for 15-min walkthrough
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt                          # List of dependencies
````

---

## ğŸ§ª Datasets Used

* **BSD68** â€“ Standard benchmark for synthetic noise
* **Set12** â€“ Widely used in low-level vision tasks
* **RealNoise** â€“ Smartphone-captured noisy images (no clean ground truths)

---

## ğŸ“Š Evaluation Metrics

* **PSNR**: Peak Signal-to-Noise Ratio
* **SSIM**: Structural Similarity Index

---

## ğŸ“¦ Installation & Dependencies

Clone the repo and install the dependencies:

```bash
git clone https://github.com/your-username/self-supervised-image-denoising
cd self-supervised-image-denoising
pip install -r requirements.txt
```

**requirements.txt**:

```txt
torch>=1.11.0
torchvision
numpy
matplotlib
scikit-image
opencv-python
tqdm
```

---

## ğŸš€ How to Train

```bash
python train.py --dataset data/BSD68 --noise_sigma 25
```

Optional flags:

* `--epochs`: number of epochs
* `--batch_size`: batch size
* `--save_path`: model save directory

---

## ğŸ“ˆ Results Summary

| Model           | PSNR (Ïƒ=25) | SSIM | Params | Inference Time |
| --------------- | ----------- | ---- | ------ | -------------- |
| DnCNN           | 30.4 dB     | 0.88 | 560K   | 0.10 s         |
| Noise2Void      | 29.6 dB     | 0.86 | 1.4M   | 0.15 s         |
| **SelfDIL-CBN** | 30.2 dB     | 0.87 | 2.1M   | 0.12 s         |

---

## ğŸ“½ï¸ Video Presentation

A 15-minute walkthrough covering:

* Novelty of our DIL-based self-supervision
* Architecture and coding details
* Comparative evaluation
* Visual demos

Video script is in `video/video_script.txt`.

---

## âœï¸ Authors & Credits

* **Rishabh Tiwari** â€“ B.Sc. Statistics, University of Lucknow
* Inspired by:
  *"Self-supervised Image Denoising with Downsampled Invariance Loss and Conditional Blind-Spot Network"* â€“ Yeong Il Jang et al., ICCV 2023

---

## ğŸ“š Suggested Journals (for publication)

1. Signal, Image and Video Processing â€“ Springer (Q2)
2. Journal of Electronic Imaging â€“ SPIE (Q2)
3. IET Image Processing â€“ Wiley (Q2)
4. Journal of Real-Time Image Processing â€“ Springer (Q3)
5. EURASIP Journal on Image and Video Processing â€“ SpringerOpen (Q3, open access)

---

## ğŸ”– License

This project is for academic and non-commercial research use only.

---

